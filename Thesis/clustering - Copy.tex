\documentclass[11pt]{article} 
\usepackage[american]{babel}
\usepackage{makeidx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{xfrac}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumerate}
%\usepackage{MnSymbol}

\oddsidemargin= -12pt \evensidemargin= -12pt
\topmargin=-45pt
\binoppenalty=10000
\relpenalty=10000
\textwidth=6.5in\textheight=9in \baselineskip=18pt
\parskip=6pt plus 1pt
\numberwithin{equation}{section}

\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[proposition]


\begin{document}

%\begin{center} 
%\Large {Tel-Aviv University}
%
%\Large {The Raymond and Beverly Sackler Faculty of} \\
%\Large {Exact Sciences} \\
%\Large {The Department of Statistics and Operations} \\
%\Large {Research}
%
%\bigskip
%\bigskip
%\bigskip
%
%\Large {\bf Draft }
%
%\bigskip
%\bigskip
%\bigskip
%\bigskip
%
%\Large{Thesis Submitted Towards the Degree of Master} \\
%\Large {of Science in Operations Research}
%
%\bigskip
%
%\Large {Sergey Voldman}
%
%\bigskip
%\bigskip
%\bigskip
%
%\Large {Supervisors:} \\
%\Large {Prof. Marc Teboulle} \\
%\Large {Prof. Shoham Sabach}
%
%\bigskip
%\bigskip
%
%\Large{2015}
%
%\end{center}
%
%\newpage
%
%\begin{center} \Large {\bf Draft}
%\end{center}
%
%\begin{abstract} 
%
%To-do...
%
%\newpage
%
%\end{abstract}
%
%\section{Introduction}
%
%To-do...
%

\newpage

\section{The Clustering Problem}

Let $\mathcal{A}= \left\lbrace a^1, \dots ,a^m \right\rbrace$ be a given set of points in $\mathbb{R}^n$, and let $1 < k < m$ be a fixed given number of clusters. The clustering problem consists of partitioning the data $\mathcal{A}$ into $k$ subsets $\left\lbrace A^1, \dots ,A^k \right\rbrace$, called clusters. For each $l=1, \cdots ,k$, the cluster $A_l$ is represented by its center $x^l$, and we want to determine $k$ cluster centers $\left\lbrace x_1, \cdots ,x_k \right\rbrace$ such that the sum of proximity measures from each point $a^i$ to a nearest cluster center $x^l$ is minimized.

The clustering problem formulation is given by

\begin{equation}
	\min\limits_{x^1, \dots ,x^k \in \mathbb{R}^n} \sum\limits_{i=1}^{m} \min\limits_{1 \le l \le k} d(x^l,a^i) , \label{StateEq1}
\end{equation}

\noindent with $\textit{d}(\cdot ,\cdot)$ being a distance-like function.

\section{Problem Reformulation and Notations}

We introduce some notations that will be used throughout this document.

\noindent $A = (a^1, \cdots , a^m) \in \left(\mathbb{R}^n\right)^m$, where $a^i \in \mathbb{R}^n,\smallskip i=1, \cdots , m$

\noindent $W = (w^1, \cdots , w^m) \in \left(\mathbb{R}^k\right)^m$, where $w^i \in \mathbb{R}^k,\smallskip i=1, \cdots , m$

\noindent $X = (x^1, \cdots , x^k) \in \left(\mathbb{R}^n\right)^k$, where $x^l \in \mathbb{R}^n,\smallskip l=1, \cdots , k$

\noindent $d^{i}(X) = (d(x^1,a^i), \cdots , d(x^k,a^i)) \in \mathbb{R}^k,\smallskip i=1, \cdots , m$

\noindent $\Delta = \left\lbrace u \in \mathbb{R}^k \mid \sum\limits_{l=1}^{k} u_l = 1, u_l \geq 0 , l=1, \dots ,k \right\rbrace$

\noindent For some $S \subseteq \mathbb{R}^n$, $\delta_S(p) = \begin{cases} 0 &\mbox{if } p \in S \\ 
\infty &\mbox{if } p \not\in S \end{cases}$

\noindent $\langle u,v \rangle = \sum\limits_{l=1}^{k} u_l \cdot v_l$, for $u,v \in \mathbb{R}^k$

Using the functional optimization representation of minimum of $k$ values, i.e. $\min\limits_{1 \leq l \leq k} u_l = \newline \min \left\lbrace \langle u,v \rangle \mid v \in \Delta \right\rbrace$, and applying it over $\left(\ref{StateEq1}\right)$, gives a smooth reformulation of the clustering problem

\begin{equation}
	\min\limits_{X \in \left(\mathbb{R}^n\right)^k} \sum\limits_{i=1}^{m} \min\limits_{w^i \in \Delta} \langle w^i , d^i(X) \rangle \label{StateEq2}
\end{equation}

Further replacing the constrain over $w^i$ with $\delta(\cdot)$ function results in a equivalent formulation

\begin{equation}
	\min\limits_{X \in \left(\mathbb{R}^n\right)^k , W \in \left(\mathbb{R}^k\right)^m} \left\lbrace \sum\limits_{i=1}^{m} \langle w^i , d^i(X) \rangle + \delta_{\Delta}(w^i) \right\rbrace \label{StateEq3}
\end{equation}

Finally, introducing few more useful definitions, for each $i=1, \cdots , m$

\begin{center}
$H_i(W,X) = \langle w^i , d^i(X) \rangle$
\\ \smallskip
$G(w^i) = \delta_{\Delta}(w^i)$
\\ \smallskip
$H(W,X) = \sum\limits_{i=1}^{m} H_i(W,X)$
\\ \smallskip
 $G(W) = \sum\limits_{i=1}^{m} G(w^i)$
\\
\end{center}

Replacing the terms in (\ref{StateEq2}) with the function above gives final equivalent clustering problem formulation

\begin{equation}
	\min \left\lbrace H(W,X) + G(W) \mid X \in (\mathbb{R}^n)^k , W \in (\mathbb{R}^k)^m \right\rbrace \label{StateEq4}
\end{equation}




\section{Clustering via PALM approach }

An equivalent smooth formulation to the clustering problem


PALM algorithms addresses nonconvex-nonsmooth problems of the form

\begin{equation}
	minimize_{x,y} \Psi(x,y):=f(x)+g(y)+H(x,y) , \label{StateEq13}
\end{equation}

\noindent and in the extended form for \textit{p} blocks

\begin{equation}
	minimize\left\lbrace \Psi(x_1, \dots ,x_p):= \sum\limits_{i=1}^{p}f_i(x_i)+H(x_1, \dots ,x_p) : x_i \in \mathbb{R}^{n_i} \right\rbrace , \label{StateEq14}
\end{equation}

\noindent where $H : \mathbb{R}^N \rightarrow \mathbb{R}$ with $N= \sum^{p}_{i=1} n_i$ is assumed to be $C^1$ and each $f_i , i= 1, \dots ,p$, is proper and lower-semicontinuous function.

Applying the PALM notations to the clustering problem formulation (1.2), with distance-like function $d(u,v)= \| u-v \|^2$, setting $f_l(x^l)= \delta_S(x^l)$, $l=1, \dots ,k $, $g_i(w^i)= \delta_{\Delta^i}(w^i)$, $i=1, \dots ,m$ and $H(x^1, \dots ,x^k,w^1, \dots ,w^m)= \sum\limits_{i=1}^{m} v_i \sum\limits_{l=1}^{k} w^i_l d(x^l , a^i)$.

Next, we confirm all requirements of $f_l$, $g_i$ and $H$ as listed in Assumptions 1 and 2 at (reference to PALM article). For simplicity, we introduce some notations ${\bf x} = (x^1, x^{2} , \ldots ,x^{k})$ and similarly ${\bf w} = (w^1, w^{2} , \ldots ,w^{m})$. Also ${\bf x}^{-l} = (x^1, \ldots ,x^{l-1}, x^{l+1}, \ldots ,x^{k})$ and similarly \\ ${\bf w}^{-i} = (w^1, \ldots ,w^{i-1}, w^{i+1}, \ldots ,w^{m})$.
\begin{enumerate}[(i)]
  \item Since $f_l,g_i,H \geq 0$ they all are proper. $g_i$ and $H$ are lower semicontinuous since $\Delta_i$ is closed and $H$ in $C^2$. As for lower semicontinuity of $f_l$ it requires $S$ to be closed.
  \item The partial gradient $\nabla_{x^l}H(\textbf{x}, \textbf{w})$ is globally Lipschitz with moduli $L_{x^l}({\bf x}^{-l}, {\bf w})=2\sum\limits_{i=1}^{m} v_i w_l^i \leq \\ \leq 2w_{l}^{max}\sum\limits_{i=1}^{m} v_i = 2w_{l}^{max}$, for $l=1, \dots ,k$, where $w^{max}_l:=\max\limits_{i=1, \cdots ,m} w^i_l$.
  \item $H$ is linear with respect to ${\bf w}$ thus $\nabla_{x^l}H(\textbf{x}, \textbf{w})$ is globally Lipschitz with moduli $L_{w^i}({\bf x}, {\bf w}^{-i})=0$, for $i=1, \dots ,m$. For PALM's proximal steps remain always well-defined, we set \\ $L_{w^i}({\bf x}, {\bf w}^{-i})= \mu_i > 0$, for $i=1, \dots ,m$ (see Remark 3 (iii)). Similarly, in case $L_{x^l}({\bf x}^{-l}, {\bf w})$ is too close to $0$, we set $L_{x^l}({\bf x}^{-l}, {\bf w}) = \nu_l >0$, for $l=1, \cdots ,k$.
%  \item $\| \nabla_{x^l}H(x^1, \dots ,x^{l-1},s,x^{l+1}, \dots ,x^k, \textbf{w}) - \nabla_{x^l}H(x^1, \dots ,x^{l-1},t,x^{l+1}, \dots ,x^k, \textbf{w}) \| = \\ \| \sum\limits_{i=1}^{m} v_i w_l^i \cdot 2(s-a^i) - \sum\limits_{i=1}^{m} v_i w_l^i \cdot 2(s-a^i) \| = 2\sum\limits_{i=1}^{m} v_i w_l^i \| s-t \| \leq 2 \| s-t \|$, thus the partial gradient $\nabla_{x^l}H$ is globally Lipschitz with moduli $L_{x^l}(\cdot)=2$, for $l=1, \dots ,k$.\\
%  Also, $\| \nabla_{w^i}H(\textbf{x},w^1, \dots ,w^{i-1},s,w^{l+1}, \dots ,w^m) - \nabla_{w^i}H(\textbf{x},w^1, \dots ,w^{i-1},t,w^{l+1}, \dots ,w^m) \| = \\ \| (v_i \|x^1 - a^i \|, \dots ,v_i\|x^k - a^i\|)^T - (v_i \|x^1 - a^i \|, \dots ,v_i\|x^k - a^i\|)^T \| = 0$, thus the partial gradient $\nabla_{w^i}H$ is globally Lipschitz with moduli $L_{w^i}(\cdot)=0$, for $i=1, \dots ,m$.
%  \item $\inf \left\lbrace L_{x^l}(\cdot) \right\rbrace = \inf \left\lbrace L_{w^i}(\cdot) \right\rbrace =0 \ngtr 0$ (this is a problem) 
%  and $\sup \left\lbrace L_{x^l}(\cdot) \right\rbrace = \sup \left\lbrace L_{w^i}(\cdot) \right\rbrace =2.$
  \item $\inf \left\lbrace L_{w^i}({\bf x}, {\bf w}^{-i}) \right\rbrace = \sup \left\lbrace L_{w^i}({\bf x}, {\bf w}^{-i}) \right\rbrace = \mu_i, i=1, \cdots ,m$ \\ and $\sup \left\lbrace L_{x^l}({\bf x}^{-l}, {\bf w}) \right\rbrace \leq 2w^{max}_l$, $\inf \left\lbrace L_{x^l}({\bf x}^{-l}, {\bf w}) \right\rbrace\geq \nu_l, l=1, \cdots ,k$.
  \item $\nabla H$ is Lipschitz continuous on bounded subset, since $H$ in $C^2$ (see Remark 3 (iv)).
  \item PALM requires $\Psi$ to be KL function. $H$ is real polynomial function, thus satisfies the KL property. $\Delta_i$ is semi-algebraic set, and we require $S$ to be semi-algebraic set.
\end{enumerate}

Next, we formulate PALM's steps for the clustering problem, and explicitly compute the proximal formulas.

{\bf PALM-Clustering}
\begin{enumerate}[(1)]
  \item Initialization: Select random vectors $x^{l,0} \in S, l=1, \cdots ,k$ and $w^{i,0} \in \Delta^i, i=1 \cdots ,m$.
  \item For each $t=0,1, \cdots$ generate a sequence $\left\lbrace (x^{1,t}, \cdots , x^{k,t}, w^{1,t}, \cdots ,w^{m,t}) \right\rbrace_{t \in \mathbb{N}}$ as follows:
  \begin{enumerate}[(2.1)]
  	\item For each $l=1, \cdots ,k $ compute:
  	\begin{enumerate}[(2.1.1)]
  		\item Take $\gamma_l>1$, set $c^t_l = \gamma_l L_{x^l}(x^{1,t+1}, \cdots, x^{l-1,t+1}, x^{l+1,t}, \cdots ,x^{k,t}, w^{1,t}, \cdots ,w^{m,t})$ and compute
  		\begin{center}
  			$x^{l,t+1} \in prox^{f_l}_{c^t_l}(x^{l,t} - \frac{1}{c^t_l}\nabla_{x^l}H(x^{1,t+1}, \cdots, x^{l-1,t+1}, x^{l,t}, x^{l+1,t}, \cdots ,x^{k,t}, w^{1,t}, \cdots ,w^{m,t}))$ \\ $= \Pi_S \left( x^{l,t} - \frac{\sum\limits_{i=1}^m v_iw^{i,t}_l 2(x^{l,t}-a^i)}{\gamma_l \max \left\lbrace \nu_l, 2\sum\limits_{i=1}^m v_iw^{i,t}_l \right\rbrace}\right) = \Pi_S \left( x^{l,t}\left(1- \frac{\sum\limits_{i=1}^m v_iw^{i,t}_l}{\gamma_l \max \left\lbrace \frac{\nu_l}{2}, \sum\limits_{i=1}^m v_iw^{i,t}_l \right\rbrace}\right) + \frac{\sum\limits_{i=1}^m v_iw^{i,t}_l a^i}{\gamma_l \max \left\lbrace \frac{\nu_l}{2}, \sum\limits_{i=1}^m v_iw^{i,t}_l \right\rbrace} \right)$
  		\end{center}
  	\end{enumerate}
  \end{enumerate}
  \begin{enumerate}[(2.2)]
  	\item For each $i=1, \cdots ,m $ compute:
  	\begin{enumerate}[(2.2.1)]
  		\item Take $\beta_i>1$, set $d^t_i = \beta_i L_{w^i}(x^{1,t+1}, \cdots ,x^{k,t+1}, w^{1,t+1}, \cdots ,w^{i-1,t+1}, w^{i+1,t}, \cdots ,w^{m,t})$ and compute
  		\begin{center}
  			$w^{i,t+1} \in prox^{g_i}_{d^t_i}(w^{i,t} - \frac{1}{d^t_i}\nabla_{w^i}H(x^{1,t+1}, \cdots ,x^{k,t+1}, w^{1,t+1}, \cdots ,w^{i-1,t+1}, w^{i,t}, w^{i+1,t}, \cdots ,w^{m,t})$ \\ $= \Pi_{\Delta^i}(w^{i,t} - \frac{v_i}{\beta_i \mu_i} (w^{i,t}_1 \| x^{1,t+1} - a^i \|^2, \cdots , w^{i,t}_k \| x^{k,t+1} - a^i \|^2 )^T)$ \\ $ = \Pi_{\Delta^i}((w^{i,t}_l (1 - \frac{v_i \| x^{l,t+1} - a^i \|^2}{\beta_i \mu_i} ))_{1 \leq l \leq k})$
  		\end{center}
  	\end{enumerate}
  \end{enumerate}
\end{enumerate}

\newpage

\section{Clustering via ADMM approach }

First we add new variables $z^l, l=1, \cdots ,k$, and formulate an equivalent problem to the clustering problem (see (1.2)):

\begin{equation}
	\min\limits_{x^1, \dots ,x^k \in \mathbb{R}^n} \min\limits_{w^1, \dots ,w^m \in \mathbb{R}^k} \min\limits_{z^1, \dots ,z^k \in S} \left\lbrace \sum\limits_{i=1}^{m} v_i \sum\limits_{l=1}^{k} w^i_l d(x^l , a^i) \mid w^i \in \Delta^i , i=1, \dots ,m , x^l = z^l, l=1, \dots ,k \right\rbrace
\end{equation}

We present the augmented Lagrangian associated with the clustering problem

\begin{equation}
	L_\rho({\bf x},{\bf z},{\bf y},{\bf w}) = H({\bf x},{\bf w}) + \sum\limits_{l=1}^k (y^l)^T (x^l -z^l) + \frac{\rho}{2} \sum\limits_{l=1}^k \| x^l -z^l \|^2
\end{equation}

\noindent ADMM update:
\begin{center}
	$x^{l,t+1} := \frac{\rho z^{l,t} - y^{l,t} + 2\sum\limits_{i=1}^m {v_i w^{i,t}_l a^i} }{\rho + 2\sum\limits_{i=1}^m v_i w^{i,t}_l}$ \\ \bigskip
	$z^{l,t+1} := \Pi_S(x^{l,t+1} + \frac{y^{l,t}}{\rho} )$ \\ \bigskip
	$y^{l,t+1} := y^{l.t} + \rho (x^{l,t+1} - z^{l,t+1})$ \\ \bigskip
	$w^{i,t+1} \in \left\lbrace w \in \mathbb{R}^k \mid w \in \Delta^i,\text{ such that if }l \not\in Nearest({\bf x}^{t+1} ,a^i) \text{ then } w^i_l=0 \right\rbrace $
\smallskip
	$\text{where } Nearest({\bf x} ,a^i) := \left\lbrace 1 \leq l \leq k \mid \|x^l -a^i\|= \min\limits_{1 \leq j \leq k} \|x^j - a^i\| \right\rbrace$
\end{center}

\newpage

\noindent


%\begin{thebibliography}{99}

%\end{thebibliography}



\end{document}
